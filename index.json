[{"authors":null,"categories":null,"content":"I am a PhD student and scientific assistant working with Steffen Staab and Ralf Lämmel. My research focus is programming with semantic data or graph data. I\u0026rsquo;m mainly looking into avoiding errors in programs that query and process such kind of data through type systems.\nI studied Computer Science at the Johannes Gutenberg University in Mainz as well as in the University of Koblenz-Landau. In my bachelor studies at Mainz, my main focus was on Computer Graphics, Web Technologies and Databases. I was also involved in student teaching for the Programming Languages and Software Engineering courses. I received my Bachelor degree in 2011. For my masters degree, I switched to the University of Koblenz-Landau. During my studies in Koblenz, I was mostly involved in the 101companies software chrestomathy by Ralf Lämmel and the Software Languages team. I received my Master degree in 2013.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"I am a PhD student and scientific assistant working with Steffen Staab and Ralf Lämmel. My research focus is programming with semantic data or graph data. I\u0026rsquo;m mainly looking into avoiding errors in programs that query and process such kind of data through type systems.\nI studied Computer Science at the Johannes Gutenberg University in Mainz as well as in the University of Koblenz-Landau. In my bachelor studies at Mainz, my main focus was on Computer Graphics, Web Technologies and Databases.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":["Philipp Seifer","Johannes Härtel","Martin Leinberger","Ralf Lämmel","Steffen Staab"],"categories":null,"content":"","date":1546297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546297200,"objectID":"ffadbb014a7454b1f762547e8bee44ca","permalink":"/publication/graph-query-analysis/","publishdate":"2019-01-01T00:00:00+01:00","relpermalink":"/publication/graph-query-analysis/","section":"publication","summary":"","tags":null,"title":"Empirical study on the usage of graph query languages in open sourceJava projects","type":"publication"},{"authors":["Philipp Seifer","Martin Leinberger","Ralf Lämmel","Steffen Staab"],"categories":null,"content":"","date":1546297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546297200,"objectID":"dd73dc8dc3b0451e7a41d8955e5b8de5","permalink":"/publication/scaspa/","publishdate":"2019-01-01T00:00:00+01:00","relpermalink":"/publication/scaspa/","section":"publication","summary":"Graph-based data models allow for flexible data representation. In\nparticular, semantic data based on RDF and OWL fuels use cases ranging from\ngeneral knowledge graphs to domain specific knowledge in various technological\nor scientific domains.  The flexibility of such approaches, however, makes\nprogramming with semantic data tedious and error-prone. In particular the\nlogics-based data descriptions employed by OWL are problematic for existing\nerror-detecting techniques, such as type systems.  In this paper, we present\nDOTSpa, an advanced integration of semantic data into programming. We embed\ndescription logics, the logical foundations of OWL, into the type checking\nprocess of a statically typed programming language and provide typed data access\nthrough an embedding of the query language SPARQL. In addition, we demonstrate\na concrete implementation of the approach, by extending the Scala programming\nlanguage.  We qualitatively compare programs using our approach to equivalent\nprograms using a state-of-the-art library, in terms of how both frameworks aid\nusers in the handling of typical failure scenarios.","tags":null,"title":"Semantic Query Integration With Reason","type":"publication"},{"authors":["Martin Leinberger","Ralf Lämmel","Steffen Staab"],"categories":null,"content":"","date":1483225200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483225200,"objectID":"5a1474588dc7bfa5bee1bb9f5e012fe9","permalink":"/publication/lambda-dl/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/publication/lambda-dl/","section":"publication","summary":"Semantic data fuels many different applications, but is still \nlacking proper integration into programming languages. Untyped \naccess is error-prone. Mapping approaches cannot fully capture the \nconceptualization of semantic data. In this paper, we present \n${\\lambda\\_{DL}}$, a typed ${\\lambda}$-calculus with constructs for \noperating on semantic data. This is achieved by the integration of \ndescription logics into the ${\\lambda}$-calculus for both typing and \ndata access or querying. The language is centered around several \nkey design principles, in particular: (1) the usage of semantic \nconceptualizations as types, (2) subtype inference for these \ntypes, and (3) type-checked query access to the data by both \nensuring the satisfiability of queries as well as typing query \nresults precisely. The paper motivates the use of a designated \ntype system for semantic data and it provides the theoretic \nfoundation for the integration of description logics as well as \nthe core formal definition of ${\\lambda\\_{DL}}$ including a proof of \ntype safety.","tags":null,"title":"The Essence of Functional Programming on Semantic Data","type":"publication"},{"authors":["Carsten Hartenfels","Martin Leinberger","Ralf Lämmel","Steffen Staab"],"categories":null,"content":"","date":1483225200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483225200,"objectID":"7c104482c37c872ac07f8179274f078a","permalink":"/publication/semantics-4-j/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/publication/semantics-4-j/","section":"publication","summary":"Programming with OWL is error-prone due to the lack of type-safe\nintegration into programming languages. While generic types such as *Resource*\ncan represent anything the data can model, they make it impossible to\nerror-check programs. Mapping ontological concepts into types of the programming\nlanguage on the other hand often cannot capture the ontology completely and\nduplicates knowledge that a semantic reasoner already has. Semantics4J, an\nextended Java compiler, allows for type-safe programming with OWL by integrating\nDL expressions as types and values into the programming language. This paper\npresentsa prototype that supports our theoretical concept\n[${\\lambda\\_{DL}}$](/publication/lambda-dl/) by relying on an extended\ntype-checking process building upon a reasoner as well as class expression\nqueries that are being used as types themselves.","tags":null,"title":"Type-Safe Programming with OWL in Semantics4J","type":"publication"},{"authors":["Martin Leinberger","Ralf Lämmel","Steffen Staab"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"87d3f7e0b1f0e7387385b84c520bd9e2","permalink":"/publication/lambdadl-preliminary/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/lambdadl-preliminary/","section":"publication","summary":"Semantic data fuels many different applications, but is still \nlacking proper integration into programming languages. Untyped \naccess is error-prone. Mapping approaches cannot fully capture the \nconceptualization of semantic data. In this paper, we present \n${\\lambda\\_{DL}}$, a typed ${\\lambda}$-calculus with constructs for \noperating on semantic data. This is achieved by the integration of \ndescription logics into the ${\\lambda}$-calculus for both typing and \ndata access or querying. The language is centered around several \nkey design principles, in particular: (1) the usage of semantic \nconceptualizations as types, (2) subtype inference for these \ntypes, and (3) type-checked query access to the data by both \nensuring the satisfiability of queries as well as typing query \nresults precisely. The paper motivates the use of a designated \ntype system for semantic data and it provides the theoretic \nfoundation for the integration of description logics as well as \nthe core formal definition of ${\\lambda\\_{DL}}$ including a proof of \ntype safety.","tags":null,"title":"LambdaDL: Syntax and Semantics (Preliminary Report)","type":"publication"},{"authors":["Stefan Scheglmann","Martin Leinberger","Thomas Gottron","Steffen Staab","Ralf Lämmel"],"categories":null,"content":"","date":1451602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451602800,"objectID":"2e822afe1a92379d7f8d699e536c6f19","permalink":"/publication/sepal/","publishdate":"2016-01-01T00:00:00+01:00","relpermalink":"/publication/sepal/","section":"publication","summary":"The Linked Data cloud provides a large collection of interlinked\ndata and is supposed to be seen as one, big data source. However, when\ndeveloping applications against this data source, it becomes apparent that\ndifferent challenges arise in the various steps of programming. Among these are\nthe selection and conceptualization of data as well as the process of actually\naccessing the data. The SEPAL (Schema Enhanced Programming for Linked Data)\nProject provides a new approach for integrating Linked Data sources when\ndeveloping Semantic Web applications. It does this by crawling the LoD cloud,\nanalyzing the extracted data and providing this information to a developer\nduring development through a framework that extends the programing language.  In\nthis paper, we will motivate the necessity for a project like SEPAL and explain\nthe core components of the project.","tags":null,"title":"SEPAL: Schema Enhanced Programming for Linked Data","type":"publication"},{"authors":["Ralf Lämmel","Martin Leinberger","Thomas Schmorleiz","Andrei Varanovich"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"47312e73f0b45d5ed4b8e0e74b6d9335","permalink":"/publication/feature-comparison/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/feature-comparison/","section":"publication","summary":"We describe and validate a method for comparing programming\nlanguages or technologies or programming styles in the context of implementing\ncertain programming tasks. To this end, we analyze a number of `little software\nsystems' readily implementing a common feature set. We analyze source code,\nstructured documentation, derived metadata, and other computed data. More\nspecifically, we compare these systems on the grounds of the NCLOC metric while\ndelegating more advanced metrics to future work. To reason about feature\nimplementations in such a multi-language and multi-technological setup, we rely\non an infrastructure which enriches traditional software artifacts (i.e., files\nin a repository) with additional metadata for implemented features as well as\nused languages and technologies. All resources are organized and exposed\naccording to Linked Data principles so that they are conveniently explorable;\nboth programmatic and interactive access is possible. The relevant formats and\nthe underlying ontology are openly accessible and documented.","tags":null,"title":"Comparison of feature implementations across languages,technologies,\nand styles","type":"publication"},{"authors":["Ralf Lämmel","Andrei Varanovich","Martin Leinberger","Thomas Schmorleiz","Jean-Marie Favre"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"ca67e8e8f4a8735ac3e8745b4882eda9","permalink":"/publication/decl-devel-tutorial/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/decl-devel-tutorial/","section":"publication","summary":"Software development could be said to be declarative, if\ndeclarative programming languages were used significantly in the development of\na software system. Software development could also be said to be declarative, if\nlightweight or heavyweight formal methods or model-driven engineering and model\ntransformation were used as the primary development methods. This tutorial\ndiscusses another view on 'declarative software development'. That is, we\npromote the use of declarative methods for understanding software systems,\nsoftware languages, software technologies, and software concepts. More\nspecifically, we discuss a method package of a software ontology, automated\nsoftware analysis, a modeling approach for software technologies, and Linked\nData-based publication and exploration of software data.","tags":null,"title":"Declarative Software Development: Distilled Tutorial","type":"publication"},{"authors":["Stefan Scheglmann","Ralf Lämmel","Martin Leinberger","Steffen Staab","Matthias Thimm","Evelyne Viegas"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"bcd452f8054705e4fd74d58d38a9bdab","permalink":"/publication/ide-integrated/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/ide-integrated/","section":"publication","summary":"In order to access RDF data in Software development, one needs to\ndeal with challenges concerning the integration of one or several RDF data\nsources into a host programming language. LITEQ allows for exploring an RDF data\nsource and mapping the data schema and the data itself from this RDF data source\ninto the programming environment for easy reuse by the developer. Core to LITEQ\nis a novel kind of path query language, NPQL, that allows for both extensional\nqueries returning data and intensional queries returning class descriptions.\nThis demo presents a prototype of LITEQ that supports such a type mapping as\nwell as autocompletion for NPQL queries.","tags":null,"title":"IDE Integrated RDF Exploration, Access and RDF-Based Code Typing with\nLITEQ","type":"publication"},{"authors":["Steffen Staab","Stefan Scheglmann","Martin Leinberger","Thomas Gottron"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"d5ca61556ad444ef118431b8dc6029af","permalink":"/publication/programming-sem-web/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/programming-sem-web/","section":"publication","summary":"The Semantic Web changes the way we deal with data, because\nassumptions about the nature of the data that we deal with differ substantially\nfrom the ones in established database approaches. Semantic Web data is (i)\nprovided by different people in an ad-hoc manner, (ii) distributed, (iii)\nsemi-structured, (iv) (more or less) typed, (v) supposed to be used\nserendipitously. In fact, these are highly relevant assumptions and challenges,\nsince they are frequently encountered in all kind of data-centric challenges\nalso in cases where Semantic Web standards are not in use. However, they are\nonly partially accounted for in existing programming approaches for Semantic Web\ndata including (i) semantic search, (ii) graph programming, and (iii)\ntraditional database programming approaches. The main hypothesis of this talk is\nthat we have not yet developed the right kind of programming paradigms to deal\nwith the proper nature of Semantic Web data, because none of the mentioned\napproaches fully considers its characteristics. Thus, we want to outline\nempirical investigations of Semantic Web data and recent developments towards\nSemantic Web programming that target the reduction of the impedance mismatches\nbetween data engineering and programming approaches.","tags":null,"title":"Programming the Semantic Web","type":"publication"},{"authors":["Stefan Scheglmann","Martin Leinberger","Ralf Lämmel","Steffen Staab","Matthias Thimm"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"75d8588e9bd2ac72597225ad6516edb6","permalink":"/publication/property-based-typing/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/property-based-typing/","section":"publication","summary":"Coding against the semantic web can be quite difficult as the\nbasic concepts of RDF data and programming languages differ greatly. Existing\nmappings from RDF to programming languages are mostly schema-centric. However,\nthis can be problematic as many data sources lack schematic information. To\nalleviate this problem, we present a data centric approach that focuses on the\nproperties of the instance data found in RDF and that lets a developer create\ntypes in his programming language by specifying properties that need to be\npresent. This resembles a type definition rooted in description logics. We show\nhow such a type definition can look like and demonstrate how a program using\nsuch type definitions can can be written.","tags":null,"title":"Property-based typing with LITEQ","type":"publication"},{"authors":["Martin Leinberger","Stefan Scheglmann","Ralf Lämmel","Steffen Staab","Matthias Thimm","Evelyne Viegas"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"86da44856c3975c000f01913438f6667","permalink":"/publication/liteq/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/liteq/","section":"publication","summary":"The Semantic Web is intended as a web of machine readable\ndata where every data source can be the data provider for different kinds of\napplications. However, due to a lack of support it is still cumbersome to work\nwith RDF data in modern, object-oriented programming languages, in particular if\nthe data source is only available through a SPARQL endpoint without further\ndocumentation or published schema information. In this setting, it is desirable to\nhave an integrated tool-chain that helps to understand the data source during\ndevelopment and supports the developer in the creation of persistent data\nobjects. To tackle these issues, weintroduce LITEQ, a paradigm for integrating\nRDF data sources intoprogramming languages and strongly typing the\ndata. Additionally, we report on two use cases and show that compared to existing\napproaches LITEQ performs competitively according to the Halstead metric.","tags":null,"title":"Semantic Web Application Development with LITEQ","type":"publication"},{"authors":["Jean-Marie Favre","Ralf Lämmel","Martin Leinberger","Thomas Schmorleiz","Andrei Varanovich"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"4b0f2ad70baf51b36f090700d23f3e96","permalink":"/publication/linking-code-doc/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/linking-code-doc/","section":"publication","summary":"The software chrestomathy of the 101companies community project\ndemonstrates 'many' software languages and software technologies by implementing\n'many' variants of a human resources management system, each implementation\nselects from 'many' optional features. All implementations are available through\na source-code repository and they are documented on a wiki. Source code and\ndocumentation encode references to software languages, software technologies,\nsoftware concepts, and product features, which, by themselves, are also\ndocumented and linked on the wiki. This setup implies the challenges of\nestablishing links between source code and documentation as well as verifying\nthat source code and documentation are in agreement. We describe an approach\nthat addresses these challenges, it relies on a rule-based system which extracts\nrelevant information from source-code artifacts (e.g., information about\nlanguage and technology usage) and assigns metadata to the artifacts (e.g.,\nmethods for validation and fact extraction). The linked source-code repository\nand wiki as well as various derived information resources are available through\nthe 101ecosystem for the benefit of the reverse engineering community.","tags":null,"title":"Linking Documentation and Source Code in a Software Chrestomathy","type":"publication"}]